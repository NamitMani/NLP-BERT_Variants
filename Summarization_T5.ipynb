{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarization_T5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3899064a7aab4a119e33b24faacb4dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6e6b4c04f4a4f36977f5c9babd5bbc1",
              "IPY_MODEL_f7d60fec360a4a58a3b0929030783af6",
              "IPY_MODEL_56456dc8d2f247bc91fd441e7608fc6d"
            ],
            "layout": "IPY_MODEL_0a61a0516edc419e9fd096ff7ff55d2d"
          }
        },
        "d6e6b4c04f4a4f36977f5c9babd5bbc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_520863f8eaf64bc4b813782677b9fdb1",
            "placeholder": "​",
            "style": "IPY_MODEL_f53124936e1049b5bcabdf929b36ad2b",
            "value": "100%"
          }
        },
        "f7d60fec360a4a58a3b0929030783af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2cd5c0ab7f4ab9b8dbf146ee15c866",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95cbcb7b24ff4372b343474a55451f83",
            "value": 3
          }
        },
        "56456dc8d2f247bc91fd441e7608fc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810cd5bb7dee496cb6883e5aca93f4f4",
            "placeholder": "​",
            "style": "IPY_MODEL_ef85f33c3cc04647acd945b74ef1e6d3",
            "value": " 3/3 [00:00&lt;00:00, 62.04it/s]"
          }
        },
        "0a61a0516edc419e9fd096ff7ff55d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "520863f8eaf64bc4b813782677b9fdb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53124936e1049b5bcabdf929b36ad2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d2cd5c0ab7f4ab9b8dbf146ee15c866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95cbcb7b24ff4372b343474a55451f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "810cd5bb7dee496cb6883e5aca93f4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef85f33c3cc04647acd945b74ef1e6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d6e8cbabd024bce826b29a005931413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16e752258009403eac6a52a3d8b0f891",
              "IPY_MODEL_c49f878dbedd416e83e5aa566ff5b7cc",
              "IPY_MODEL_956b23e18941444e8195d2c7f7c9303a"
            ],
            "layout": "IPY_MODEL_0ed1f7c4a3894c9cb04f7d28ebcb6e0a"
          }
        },
        "16e752258009403eac6a52a3d8b0f891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4baffec0a7e4a01939d54abffca1b84",
            "placeholder": "​",
            "style": "IPY_MODEL_f529f9fa55614c12bbc517268d81e46f",
            "value": "100%"
          }
        },
        "c49f878dbedd416e83e5aa566ff5b7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74947b0a988f4e6a8f7aac26c2143c76",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffe4c08853c6487492d823606c173bb8",
            "value": 2
          }
        },
        "956b23e18941444e8195d2c7f7c9303a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a2fc0d61204decbef972e9960dbdfe",
            "placeholder": "​",
            "style": "IPY_MODEL_dc6ee9ca14804e47aca7191886d33bfa",
            "value": " 2/2 [00:06&lt;00:00,  2.93s/ba]"
          }
        },
        "0ed1f7c4a3894c9cb04f7d28ebcb6e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4baffec0a7e4a01939d54abffca1b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f529f9fa55614c12bbc517268d81e46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74947b0a988f4e6a8f7aac26c2143c76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe4c08853c6487492d823606c173bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05a2fc0d61204decbef972e9960dbdfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6ee9ca14804e47aca7191886d33bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ccab645109448ec83c3c5f886fae56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7873d4555204362a059f1eaeec122a6",
              "IPY_MODEL_a1a1bd4d236541c4add9c06ffacefcfc",
              "IPY_MODEL_b5cc7cf5806a428283cc28dc565e06f4"
            ],
            "layout": "IPY_MODEL_c3ecc75c2deb4ca3905dba184139ab51"
          }
        },
        "f7873d4555204362a059f1eaeec122a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dd20c5938e148ed89fe615f7f350128",
            "placeholder": "​",
            "style": "IPY_MODEL_084a656378824cc29c27382d8eaa2456",
            "value": "100%"
          }
        },
        "a1a1bd4d236541c4add9c06ffacefcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ddce0d06da4312acb794e18c60f6c2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fb59dec81f54567b8a46211f27b9a2a",
            "value": 1
          }
        },
        "b5cc7cf5806a428283cc28dc565e06f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7f9182df5344f88c06cc7f5a89b4d6",
            "placeholder": "​",
            "style": "IPY_MODEL_6d3bf69cbbd84fd499cf64444727a3ea",
            "value": " 1/1 [00:01&lt;00:00,  1.56s/ba]"
          }
        },
        "c3ecc75c2deb4ca3905dba184139ab51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd20c5938e148ed89fe615f7f350128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "084a656378824cc29c27382d8eaa2456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01ddce0d06da4312acb794e18c60f6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb59dec81f54567b8a46211f27b9a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f7f9182df5344f88c06cc7f5a89b4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d3bf69cbbd84fd499cf64444727a3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ef77a81e86242aeaa9a6e2b96c99da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a222b23f62104d0a88e0a2568a59adda",
              "IPY_MODEL_a1307ebf83ae4090b83506bdc90f71da",
              "IPY_MODEL_a1941b132ceb4c568cb8d24568e8afde"
            ],
            "layout": "IPY_MODEL_bd2ae99cc9fb4bd38514d5966455623c"
          }
        },
        "a222b23f62104d0a88e0a2568a59adda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b072a7089e74e3e8cbb8ff809a1cedb",
            "placeholder": "​",
            "style": "IPY_MODEL_a75260a067b547b896b35ecb2c6e3318",
            "value": "100%"
          }
        },
        "a1307ebf83ae4090b83506bdc90f71da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8ee2b8931746089cb0bc4bd5224131",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ef9812e8310474894cb9c050d7869f7",
            "value": 1
          }
        },
        "a1941b132ceb4c568cb8d24568e8afde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e975dac2364ec1be04c55626ef8def",
            "placeholder": "​",
            "style": "IPY_MODEL_9431db28cb2c4a89a5ed506371e0e16a",
            "value": " 1/1 [00:01&lt;00:00,  1.48s/ba]"
          }
        },
        "bd2ae99cc9fb4bd38514d5966455623c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b072a7089e74e3e8cbb8ff809a1cedb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a75260a067b547b896b35ecb2c6e3318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e8ee2b8931746089cb0bc4bd5224131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef9812e8310474894cb9c050d7869f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43e975dac2364ec1be04c55626ef8def": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9431db28cb2c4a89a5ed506371e0e16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamitMani/NLP-BERT_Variants/blob/main/Summarization_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4cRE8IbIrIV"
      },
      "source": [
        "# Summarization\n",
        "## This notebook outlines the concepts behind finetuning a Summarization model using T-5 BERT variant model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITAczsmB8ixa",
        "outputId": "f3dd7195-5281-431f-bcd5-5370cfff26dc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnz7a6XurY9o"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a43c48f-73b5-422f-d8d9-5d0cb61d408d"
      },
      "source": [
        "! pip install -q datasets transformers rouge-score nltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 346 kB 21.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 49.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 58.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 48.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 73.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 9.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 78.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 46.0 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJBSTyZIrIb"
      },
      "source": [
        "# Fine-tuning a model on a summarization task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTCFado4IrIc"
      },
      "source": [
        "In this notebook, we will see how to fine-tune one of the [🤗 Transformers](https://github.com/huggingface/transformers) model for a summarization task. We will use the [XSum dataset](https://arxiv.org/pdf/1808.08745.pdf) (for extreme summarization) which contains BBC articles accompanied with single-sentence summaries.\n",
        "\n",
        "![Widget inference on a summarization task](https://github.com/huggingface/notebooks/blob/master/examples/images/summarization.png?raw=1)\n",
        "\n",
        "We will see how to easily load the dataset for this task using 🤗 Datasets and how to fine-tune a model on it using the `Trainer` API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVlV5Y9Km47V"
      },
      "source": [
        "model_checkpoint = \"t5-small\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RRkXuteIrIh"
      },
      "source": [
        "This notebook is built to run  with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a sequence-to-sequence version in the Transformers library. Here we picked the [`t5-small`](https://huggingface.co/t5-small) checkpoint. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7QYTpxXIrIl"
      },
      "source": [
        "We will use the [🤗 Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreSlFmlIrIm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3899064a7aab4a119e33b24faacb4dfd",
            "d6e6b4c04f4a4f36977f5c9babd5bbc1",
            "f7d60fec360a4a58a3b0929030783af6",
            "56456dc8d2f247bc91fd441e7608fc6d",
            "0a61a0516edc419e9fd096ff7ff55d2d",
            "520863f8eaf64bc4b813782677b9fdb1",
            "f53124936e1049b5bcabdf929b36ad2b",
            "9d2cd5c0ab7f4ab9b8dbf146ee15c866",
            "95cbcb7b24ff4372b343474a55451f83",
            "810cd5bb7dee496cb6883e5aca93f4f4",
            "ef85f33c3cc04647acd945b74ef1e6d3"
          ]
        },
        "outputId": "f14d7295-e9b4-4ab0-b3bd-104e7e1d28c1"
      },
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "raw_datasets = load_dataset(\"xsum\")\n",
        "metric = load_metric(\"rouge\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset xsum (/root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3899064a7aab4a119e33b24faacb4dfd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.dataset_dict import DatasetDict\n",
        "train_dataset = raw_datasets[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "val_dataset = raw_datasets[\"validation\"].shuffle(seed=42).select(range(1000))\n",
        "test_dataset = raw_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "raw_datasets = DatasetDict({\"train\":train_dataset,\"validation\":val_dataset, \"test\":test_dataset})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-wd762c7EWr",
        "outputId": "f4f1ff56-8e44-4464-d650-a490fa3daf24"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934/cache-cdf5497ad00285d3.arrow\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934/cache-fd6a73959df5c803.arrow\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934/cache-5ac33534bf69a8ea.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzfPtOMoIrIu"
      },
      "source": [
        "The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWiVUF0jIrIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0dcd58-67d7-4263-bba0-4a0e2fdf8569"
      },
      "source": [
        "raw_datasets"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3EtYfeHIrIz"
      },
      "source": [
        "To access an actual element, you need to select a split first, then give an index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6HrpprwIrIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c4d571-5f10-406c-9e80-6611cb7a9c14"
      },
      "source": [
        "raw_datasets[\"train\"][0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': 'In Wales, councils are responsible for funding and overseeing schools.\\nBut in England, Mr Osborne\\'s plan will mean local authorities will cease to have a role in providing education.\\nAcademies are directly funded by central government and head teachers have more freedom over admissions and to change the way the school works.\\nIt is a significant development in the continued divergence of schools systems on either side of Offa\\'s Dyke.\\nAnd although the Welsh Government will get extra cash to match the money for English schools to extend the school day, it can spend it on any devolved policy area.\\nMinisters have no plans to follow suit.\\nAt the moment, governing bodies are responsible for setting school hours and they need ministerial permission to make significant changes.\\nThere are already more than 2,000 secondary academies in England and its extension to all state schools is unlikely to shake the Welsh Government\\'s attachment to what they call a \"community, comprehensive model\" for schools.\\nIt rejects claims that freedom given to academies can help drive up standards, and it points to academy-free Scotland as the best performing school system in the UK.\\nEducation Minister Huw Lewis said there was \"very little evidence to suggest\" academies have a positive impact in driving up standards and Wales would not be following the model.\\n\"The Tories have wasted hundreds of millions of pounds on academies and free schools and as the Chancellor finalises his budget plans to slash vital services even further, he is committing them to wasting even more on a failing endeavour.\\n\"We have no plans to introduce the chaos and waste of academies and free schools here in Wales.\"\\nNone of the main parties in May\\'s Assembly election - including the Welsh Conservatives - have said they want to introduce academies in Wales.\\nOwen Hathway, NUT Cymru\\'s policy officer, called the academy plans for England \"scandalous.\".\\n\"There is no evidence that academies work, no evidence that they raise standards, no evidence that they offer better quality education and no evidence that they are what parents and communities want,\" he said.\\n\"Certainly a commitment to comprehensive education is something we would want, and indeed expect, all parties to hold firm to in their manifestos for the forthcoming Welsh election.\"\\nBut the Welsh and English schools systems are still linked by a joint arrangement for teachers\\' pay and conditions.\\nAcademies are not tied to these pay scales so in effect Wednesday\\'s announcement will take all English schools out of the system and raise questions about the viability of an England and Wales pay and conditions structure.\\nThere is already growing momentum for the devolution of teachers\\' pay and conditions.\\nOriginally sceptical, the Welsh Labour Government is now broadly in favour.\\nSome teaching unions remain opposed because of concern that Welsh teachers would end up being paid less than those in England.\\nMr Hathway said teachers were concerned it could lead to regional pay.\\n\"At the same time we do of course recognise that the issue of pay is already becoming a grey area due to the negative changes we see taking place in England,\" he said.\\nBut an even bigger difference between the schools landscape on either side of the border, appears to make separate arrangements for pay increasingly likely in future.',\n",
              " 'id': '35821725',\n",
              " 'summary': 'As Chancellor George Osborne announced all English state schools will become academies, the Welsh Government continues to reject the model here.'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUmphG3IrI3"
      },
      "source": [
        "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3j8APAoIrI3"
      },
      "source": [
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=5):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZy5tRB_IrI7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05e910e3-f9cc-4ba7-f669-50d476010c2c"
      },
      "source": [
        "show_random_elements(raw_datasets[\"train\"])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>summary</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The North Tees and Hartlepool NHS Foundation Trust is one of nine in England found to have higher than predicted mortality rates last year.\\nThe figures include deaths in hospital, or within 30 days of discharge.\\nNorth Tees and Hartlepool NHS Trust medical director, Dr David Emerton, said it was \"reviewing the care of all patients who die\".\\nDr Emerton said the figures - higher than expected for the second year running - were skewed by the number of patients treated without being admitted to hospital.\\nSome patients, such as those in care homes nearing the end of their lives, where sent to hospital \"when not much really can be done\", he said.\\nThe Health and Social Care Information Centre (HSCIC), who compiled the data, says the categorisation does not mean a hospital is failing or unsafe and does not take levels of social deprivation into account.\\nIts figures should \"instead should be viewed as a 'smoke alarm' which requires further investigation by the trust\", a spokeswoman said.\\nThe SHMI is available from April 2010 and the latest data covers July 2013 to June 2014.\\nThe expected risk of the patient dying in hospital, or within 30 days of discharge, is estimated based on the patient's condition, age, sex and how they were admitted to hospital.\\nDr Mike Smith, from the Patients Association, said the figures should be viewed in the context of the area's poverty and unemployment rate.\\n\"If people have, locally, a high mortality and morbidity rate, that means to say people are dying more than the rest of the nation and/or are sicker than the rest of the nation, then you mustn't necessarily think it's the hospital's fault,\" he said.</td>\n",
              "      <td>More people than expected have died at a Teesside hospital trust, latest figures show.</td>\n",
              "      <td>31035720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sir Kenneth Calman, who was before the House of Lords Constitution Committee, also said he believed such a document could define what it was to be British.\\nHe told members that not enough had been done to \"articulate\" the case for the Union.\\nIn 2009, the Calman Commission recommended that Scotland take charge of half the income tax it raised.\\nHis report, which included input from the three main Unionist parties but not the SNP, came five years before the Scottish independence referendum in September 2014.\\nI don't think [the case for the Union] has been well enough articulated - it is still a case of 'them at Westminster'\\nSir Kenneth appeared before the committee - which has no SNP members - alongside Sir Paul Silk, former chairman of the Commission on Devolution in Wales.\\nCrossbench peer, Lord Judge, asked if there was merit in creating a Charter of the Union.\\nSir Kenneth replied: \"The answer is yes. I think it would make the discussion easier about who does what, and how we benefit, how you benefit and how we all benefit. I think that would be very helpful.\\n\"Without that communication, the average citizen is left wondering who does what for me now - and it is Westminster's fault anyway - so, it is easier to put it the wrong way.\"\\nSir Kenneth was also asked, by Labour peer Lord Morgan, whether such a charter should include suggestions on what it was to be British.\\nThe former chief medical officer of Scotland said: \"I think that is a good point, that seems to be part of the [means to an] end, what does it mean to be a citizen of this country and what are our values.\\n\"I can see that a group could look at a range of these issues, articulating, communicating them and seeing if people want to be part of it.\"\\nThe former commission chief added: \"I don't think [the case for the Union] has been well enough articulated - it is still a case of 'them at Westminster', as opposed to 'Westminster is here to help you'.\\n\"We need to show that it [the Union] is worthwhile, not only that Scotland has something worthwhile to contribute to the UK parliament and the UK in general, but that is what the UK is for.\"</td>\n",
              "      <td>The man who led a review of Scottish devolution has given his backing to a so-called \"Charter of the Union\".</td>\n",
              "      <td>34591295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Danny Healy-Rae told the Irish Times that issues with the N22 were caused by \"numerous fairy forts in the area\".\\nThe road had previously been repaired but problems had reappeared.\\nMr Healy-Rae said he shared local belief that \"there was something in these places you shouldn't touch\".\\nHe added that the road passed through an area that was rich in fairy folklore and magic.\\nThe N22 is the main road between Killarney in County Kerry and Cork.\\nIn Irish folklore, it is believed that disturbing areas, said to have strong connections to fairies, could bring bad luck or a curse.\\nThese areas include fairy forts, also known as raths or lios, which are the remains of hillforts or ancient circular dwellings, and fairy trees or thorn bushes.\\nSome people believe that destroying or tampering with these forts, trees or bushes, could lead to them dying young or becoming seriously ill.\\nMr Healy-Rae, an independent TD (Irish member of parliament) for County Kerry, said: \"I have a machine standing in the yard right now. And if someone told me to go out and knock a fairy fort or touch it, I would starve first.\"\\nThe issue was raised at Kerry County Council, where Mr Healy-Rae's daughter, Maura, is a councillor, last week.\\nShe told a council meeting that her father was convinced fairies were in the area of the road problems.\\nMr Healy-Rae also raised the issue at Kerry County Council in 2007 when he was a councillor, asking if a dip in the N22 near Curraglass was caused by \"fairies at work\".\\nThe Irish Times reports that the council's road department replied that it was due to a \"deeper underlying subsoil/geotechnical problem\".\\nMr Healy-Rae, whose brother Michael is also a TD, has previously hit the headlines for comments in which he denied any human impact on climate change and said that \"God above\" controlled the weather.</td>\n",
              "      <td>Bad luck caused by disturbed fairy forts is causing dips in a major road between County Kerry and County Cork, an Irish member of parliament has said.</td>\n",
              "      <td>40863737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Northumbria Police said that out of a crowd of 52,000 there were a total of 20 arrests.\\nA spokesman said: \"But both sets of fans showed that they can enjoy the passion of this game without the poison that has blighted some of the past meetings between our two clubs.\"\\nSunday's game at St James' Park ended in a 1-1 draw.\\nThe arrests - including four inside the ground - were for offences including drunk and disorderly, breach of the peace, throwing missiles, encroaching on a football pitch, and obstructing police\\nCh Supt Steve Neill said the force had worked closely with both football clubs, the local authorities, British Transport Police and the Tyne and Wear Metro.\\nHe said: \"We understand how important this fixture is to the people of this region and we recognised our policing plan needed to reflect that.\\n\"There is a lot of attention on this fixture and we want to thank the footballing community for working with us to make it a derby we can all be proud of.\"</td>\n",
              "      <td>Fans attending the Tyne-Wear derby have been praised by police for \"behaving impeccably\" at a \"very tense occasion\".</td>\n",
              "      <td>35860630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A cub escapes deep snow by hitching a ride on its mother's backside in Wapusk National Park, Manitoba, Canada.\\nTaken by Daisy Gilardini, from Switzerland, the photo is one of 25 shortlisted for the People's Choice Award in the latest Wildlife Photographer of the Year Competition - on show now at the Natural History Museum in London.\\nScroll down to see all 25 images, pre-selected by the museum from almost 50,000 submissions from 95 countries.\\nA mother's hand\\nAlain Mafart Renodier, France\\nAlain Mafart Renodier was on a winter visit to Japan's Jigokudani Snow Monkey Park when he took this photograph of a sleeping baby Japanese macaque, its mother's hand covering its head protectively.\\nOpportunistic croc\\nBence Mate, Hungary\\nAlthough this shot was taken from a safe hide, Bence Mate says it was chilling to see the killing eyes of this 4m (13ft) Nile crocodile. This one had been baited with natural carcasses on an island in the Zimanga Private Game Reserve, South Africa, but crocodiles also come here just to bask in the Sun.\\nThe stare of death\\nJohan Kloppers, South Africa\\nJohan Kloppers saw this little wildebeest shortly after it was born in the Kgalagadi Transfrontier Park, South Africa. Little did he know that he would witness its death later that same day. The small herd of wildebeest walked right past a pride of lions, and the calf was caught by a lioness and then taken by this male lion.\\nMonkey ball\\nThomas Kokta, Germany\\nCold temperatures on Shodoshima Island, Japan, sometimes lead to monkey balls, where a group of five or more snow monkeys huddle together to keep warm. Thomas Kokta climbed a tree to get this image.\\nFacing the storm\\nGunther Riehle, Germany\\nGunther Riehle arrived at the sea-ice in Antarctica in sunshine, but by the evening a storm had picked up - and then came snow. He concentrated on taking images of the emperor penguin chicks huddled together to shield themselves.\\nGhostly snow geese\\nGordon Illg, US\\nThese snow geese almost seemed like ghosts in the pink early morning light as they landed among sandhill cranes in the Bosque del Apache National Wildlife Refuge, New Mexico, US.\\nSisters\\nBernd Wasiolka, Germany\\nBernd Wasiolka encountered a large lion pride at a waterhole in the Kgalagadi Transfrontier Park, South Africa. One of the two males spray-marked the branches of a nearby tree. Later two females sniffed the markings and for a brief moment both adopted the same posture.\\nInto the fray\\nStephen Belcher, New Zealand\\nStephen Belcher spent a week photographing golden snub-nosed monkeys in a valley in the Zhouzhi Nature Reserve in the Qinling Mountains, China. The monkeys have very thick fur, which they need to withstand the freezing nights in winter. This image shows two males about to fight, one already up on a rock, the other bounding in with a young male.\\nHead-on\\nTapio Kaisla, Finland\\nTapio Kaisla took a trip to Dovrefjell-Sunndalsfjell National Park, Norway, to find these oxen in their natural habitat. Even though spring is not rutting season for these animals, they were already seriously testing their strength against each other. The air rang out with the loud bang of the head-on collision.\\nColorado red\\nAnnie Katz, US\\nIt was a crisp, clear day in January when Annie Katz saw this Colorado red fox hunting in her neighbour's field in Aspen, Colorado, US. The light was perfect, and she took the photo as the fox approached her, looking right into the lens of her camera.\\nThe couple\\nSergio Sarta, Italy\\nDuring a dive off the coast of Tulamben, Bali, Indonesia, Sergio Sarta saw a bright-coloured organism - a fire urchin with an elegant couple of little Coleman shrimps. The fire urchin has quills that are very toxic to humans - the shrimps avoid this danger by seeking out safe areas between the quills.\\nJelly starburst\\nAndrea Marshall, US\\nAndrea Marshall was snorkelling off the coast of Mozambique when she came across hundreds of large jelly-fish. Many were covered with brittle stars - opportunistic riders, taking advantage of this transport system to disperse along the coast. Delicate lighting makes the jelly glow, so the viewer can focus on the subtle colours and textures.\\nThe stand-off\\nMichael Lambie, Canada\\nIt was breeding season and all the male turkeys were putting on a show for the females, but a number of birds seemed a little confused. This one was more concerned with the potential suitor in front of it, not realising it was its own reflection.\\nInto the night\\nKarine Aigner, US\\nDuring the summer months, 20 million Mexican free-tailed bats arrive at Bracken Cave in San Antonio, Texas, US, to give birth and raise their young. Each evening at dusk, the hungry mothers emerge into the night in a vortex, circling out through the entrance and rising into the sky to feed on insects.\\nWillow up close\\nDavid Maitland, UK\\nDavid Maitland photographed the crystallised chemical salicin, which comes from willow tree bark. Salicin forms the basis of the analgesic Aspirin - no doubt this is why some animals seek out willow bark to chew on.\\nThe blue trail\\nMario Cea, Spain\\nThe kingfisher frequented this natural pond every day, and Mario Cea used a high shutter speed with artificial light to photograph it. He used several units of flash for the kingfisher and a continuous light to capture the wake as the bird dived down towards the water.\\nEye in focus\\nAlly McDowell, US/UK\\nAlly McDowell often focuses on colours and patterns underwater - and this is the eye of a parrotfish during a night dive.\\nSpiral\\nMarco Gargiulo, Italy\\nSabella spallanzanii is a species of marine polychaete, also known as a bristle worm. The worm secretes mucus that hardens to form a stiff, sandy tube that protrudes from the sand. It has two layers of feeding tentacles that can be retracted into the tube, and one of the layers forms a distinct spiral.\\nEye contact\\nGuy Edwardes, UK\\nThe Dalmatian pelican, seen here on Lake Kerkini, Greece, is the largest species of pelican in the world. It is native to eastern Europe, Russia and Asia. However, its population is currently threatened in some areas from hunting, water pollution and habitat loss, particularly a decline in wetlands.\\nConfusion\\nRudi Hulshof, South Africa\\nRudi Hulshof wanted to capture the uncertainty of the future of the southern white rhino in the Welgevonden Game Reserve, South Africa, because of poaching. He anticipated the moment when these two rhinos would walk past each other, creating this silhouette effect and the illusion of a two-headed rhino.\\nTasty delicacy\\nCristobal Serrano, Spain\\nThe natural world provides countless magical moments, none more so than the delicate moment a tiny, elegant hummingbird softly inserts its slender bill into the corolla of a flower to drink nectar. Cristobal Serrano was lucky enough to capture that exact moment in Los Quetzales National Park, Costa Rica.\\nBreakfast time\\nCari Hill, New Zealand\\nShortly after purchasing the Giraffe Manor in Nairobi, Kenya, the owners learned that the only remaining Rothschild's giraffes in the country were at risk, as their sole habitat was being subdivided into smallholdings. So they began a breeding programme to reintroduce the Rothschild's giraffe into the wild. Today, guests can enjoy visits from resident giraffes in search of a treat.\\nCaterpillar curl\\nReinhold Schrank, Austria\\nReinhold Schrank was at Lake Kerkini, Greece, taking pictures of birds, but the conditions were not ideal, so he looked for other options. He saw this caterpillar on a flower and encouraged it on to a piece of rolled dry straw. He had to work fast because the caterpillar was constantly moving.\\nRainbow wings\\nVictor Tyakht, Russia\\nThe bird's wing acts as a diffraction grating - a surface structure with a repeating pattern of ridges or slits. The structure causes the incoming light rays to spread out, bend and split into spectral colours, producing this shimmering rainbow effect.\\nVote for the People's Choice Award here before 10 January 2017.\\nThe exhibition runs until 10 September 2017.\\nTop image: Hitching a ride - by Daisy Gilardini, Switzerland.\\nA female polar bear and her cub in Wapusk National Park, Manitoba, Canada.</td>\n",
              "      <td>Wildlife Photographer of the Year is developed and produced by the Natural History Museum, London.</td>\n",
              "      <td>38083691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnjDIuQ3IrI-"
      },
      "source": [
        "The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o4rUteaIrI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7aeb60-e024-47d1-cef3-1a83107c95db"
      },
      "source": [
        "metric"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\n",
              "Calculates average rouge scores for a list of hypotheses and references\n",
              "Args:\n",
              "    predictions: list of predictions to score. Each prediction\n",
              "        should be a string with tokens separated by spaces.\n",
              "    references: list of reference for each prediction. Each\n",
              "        reference should be a string with tokens separated by spaces.\n",
              "    rouge_types: A list of rouge types to calculate.\n",
              "        Valid names:\n",
              "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
              "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
              "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
              "\"`.\n",
              "        See details in https://github.com/huggingface/datasets/issues/617\n",
              "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
              "    use_aggregator: Return aggregates if this is set to True\n",
              "Returns:\n",
              "    rouge1: rouge_1 (precision, recall, f1),\n",
              "    rouge2: rouge_2 (precision, recall, f1),\n",
              "    rougeL: rouge_l (precision, recall, f1),\n",
              "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
              "Examples:\n",
              "\n",
              "    >>> rouge = datasets.load_metric('rouge')\n",
              "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
              "    >>> references = [\"hello there\", \"general kenobi\"]\n",
              "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
              "    >>> print(list(results.keys()))\n",
              "    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
              "    >>> print(results[\"rouge1\"])\n",
              "    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n",
              "    >>> print(results[\"rouge1\"].mid.fmeasure)\n",
              "    1.0\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAWdqcUBIrJC"
      },
      "source": [
        "You can call its `compute` method with your predictions and labels, which need to be list of decoded strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XN1Rq0aIrJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0359907-75f4-4a93-b2ff-7601c7b8dc03"
      },
      "source": [
        "fake_preds = [\"hello there\", \"general kenobi\"]\n",
        "fake_labels = [\"hello there\", \"general kenobi\"]\n",
        "metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9qywopnIrJH"
      },
      "source": [
        "## Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVx71GdAIrJH"
      },
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n",
        "\n",
        "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
        "\n",
        "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
        "- we download the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXNLu_-nIrJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003b1861-cca0-45d2-f3a1-b1fde958b40b"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
            "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
            "loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5_fast.py:161: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl6IidfdIrJK"
      },
      "source": [
        "By default, the call above will use one of the fast tokenizers (backed by Rust) from the 🤗 Tokenizers library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rowT4iCLIrJK"
      },
      "source": [
        "You can directly call this tokenizer on one sentence or a pair of sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5hBlsrHIrJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b8516f-c7a6-4b1d-ab00-3729bf61ccd3"
      },
      "source": [
        "tokenizer(\"Hello, this one sentence!\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [8774, 6, 48, 80, 7142, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_0B1M2IrJM"
      },
      "source": [
        "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
        "\n",
        "Instead of one sentence, we can pass along a list of sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hkf75iwm47a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364102f3-8429-46d7-cc3c-14efe50cd7d1"
      },
      "source": [
        "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhAY2FL7m47b"
      },
      "source": [
        "To prepare the targets for our model, we need to tokenize them inside the `as_target_tokenizer` context manager. This will make sure the tokenizer uses the special tokens corresponding to the targets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qjocNSNm47b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1f9327-ac34-4423-bbbc-ddbebdcf044f"
      },
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C0hcmp9IrJQ"
      },
      "source": [
        "If you are using one of the five T5 checkpoints we have to prefix the inputs with \"summarize:\" (the model can also translate and it needs the prefix to know which task it has to perform)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq2CJSZnm47b"
      },
      "source": [
        "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
        "    prefix = \"summarize: \"\n",
        "else:\n",
        "    prefix = \"\""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a26ZMvoLm47c"
      },
      "source": [
        "We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc0BSBLIIrJQ"
      },
      "source": [
        "max_input_length = 1024\n",
        "max_target_length = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"document\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lm8ozrJIrJR"
      },
      "source": [
        "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b70jh26IrJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f911f1a2-0d54-4b79-d2af-07357413daf6"
      },
      "source": [
        "preprocess_function(raw_datasets['train'][:2])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[21603, 10, 86, 10256, 6, 6098, 7, 33, 1966, 21, 3135, 11, 12162, 53, 2061, 5, 299, 16, 2789, 6, 1363, 411, 7, 12940, 31, 7, 515, 56, 1243, 415, 5779, 56, 18682, 12, 43, 3, 9, 1075, 16, 1260, 1073, 5, 30358, 7, 33, 1461, 11264, 57, 2069, 789, 11, 819, 3081, 43, 72, 4333, 147, 7209, 7, 11, 12, 483, 8, 194, 8, 496, 930, 5, 94, 19, 3, 9, 1516, 606, 16, 8, 2925, 12355, 122, 1433, 13, 2061, 1002, 30, 893, 596, 13, 4395, 9, 31, 7, 12991, 1050, 5, 275, 2199, 8, 22982, 3141, 56, 129, 996, 1723, 12, 1588, 8, 540, 21, 1566, 2061, 12, 4285, 8, 496, 239, 6, 34, 54, 1492, 34, 30, 136, 20, 4571, 162, 26, 1291, 616, 5, 3271, 7, 43, 150, 1390, 12, 1130, 3237, 5, 486, 8, 798, 6, 3, 19585, 5678, 33, 1966, 21, 1898, 496, 716, 11, 79, 174, 6323, 23, 138, 6059, 12, 143, 1516, 1112, 5, 290, 33, 641, 72, 145, 3, 8630, 6980, 3, 9, 6615, 2720, 7, 16, 2789, 11, 165, 4924, 12, 66, 538, 2061, 19, 9909, 12, 8944, 8, 22982, 3141, 31, 7, 11352, 12, 125, 79, 580, 3, 9, 96, 18782, 485, 6, 3452, 825, 121, 21, 2061, 5, 94, 15092, 7, 3213, 24, 4333, 787, 12, 3, 9, 6615, 2720, 7, 54, 199, 1262, 95, 2443, 6, 11, 34, 979, 12, 25990, 18, 2113, 8288, 38, 8, 200, 5505, 496, 358, 16, 8, 1270, 5, 2855, 3271, 3455, 210, 9765, 243, 132, 47, 96, 8461, 385, 2084, 12, 3130, 121, 3, 9, 6615, 2720, 7, 43, 3, 9, 1465, 1113, 16, 2191, 95, 2443, 11, 10256, 133, 59, 36, 826, 8, 825, 5, 96, 634, 304, 2593, 43, 21133, 3986, 13, 4040, 13, 7051, 30, 3, 9, 6615, 2720, 7, 11, 339, 2061, 11, 38, 8, 3, 26767, 804, 23, 2260, 112, 1487, 1390, 12, 3, 7, 8058, 3362, 364, 237, 856, 6, 3, 88, 19, 3, 25345, 135, 12, 3, 26281, 237, 72, 30, 3, 9, 12385, 25654, 5, 96, 1326, 43, 150, 1390, 12, 4277, 8, 16856, 11, 2670, 13, 3, 9, 6615, 2720, 7, 11, 339, 2061, 270, 16, 10256, 535, 14794, 13, 8, 711, 2251, 16, 932, 31, 7, 11993, 4356, 3, 18, 379, 8, 22982, 23053, 7, 3, 18, 43, 243, 79, 241, 12, 4277, 3, 9, 6615, 2720, 7, 16, 10256, 5, 20412, 1626, 189, 1343, 6, 445, 6675, 6400, 51, 52, 76, 31, 7, 1291, 5502, 6, 718, 8, 25990, 1390, 21, 2789, 96, 7, 75, 232, 138, 1162, 535, 5, 96, 7238, 19, 150, 2084, 24, 3, 9, 6615, 2720, 7, 161, 6, 150, 2084, 24, 79, 3033, 2443, 6, 150, 2084, 24, 79, 462, 394, 463, 1073, 11, 150, 2084, 24, 79, 33, 125, 1362, 11, 2597, 241, 976, 3, 88, 243, 5, 96, 22243, 3, 9, 3148, 12, 3452, 1073, 19, 424, 62, 133, 241, 6, 11, 5071, 1672, 6, 66, 2251, 12, 1520, 1669, 12, 16, 70, 6571, 32, 7, 21, 8, 22316, 22982, 4356, 535, 299, 8, 22982, 11, 1566, 2061, 1002, 33, 341, 5229, 57, 3, 9, 4494, 8641, 21, 3081, 31, 726, 11, 1124, 5, 30358, 7, 33, 59, 10422, 12, 175, 726, 2643, 7, 78, 16, 1504, 2875, 31, 7, 7298, 56, 240, 66, 1566, 2061, 91, 13, 8, 358, 11, 3033, 746, 81, 8, 5931, 2020, 13, 46, 2789, 11, 10256, 726, 11, 1124, 1809, 5, 290, 19, 641, 1710, 15290, 21, 8, 20, 24817, 13, 3081, 31, 726, 11, 1124, 5, 3, 19440, 3, 7, 6873, 1950, 6, 8, 22982, 16117, 3141, 19, 230, 23971, 16, 14499, 5, 886, 2119, 7021, 7, 2367, 8560, 250, 13, 2410, 24, 22982, 3081, 133, 414, 95, 271, 1866, 705, 145, 273, 16, 2789, 5, 1363, 1626, 189, 1343, 243, 3081, 130, 4376, 34, 228, 991, 12, 3518, 726, 5, 96, 188, 17, 8, 337, 97, 62, 103, 13, 503, 16236, 24, 8, 962, 13, 726, 19, 641, 2852, 3, 9, 7592, 616, 788, 12, 8, 2841, 1112, 62, 217, 838, 286, 16, 2789, 976, 3, 88, 243, 5, 299, 46, 237, 4038, 1750, 344, 8, 2061, 3283, 30, 893, 596, 13, 8, 4947, 6, 3475, 12, 143, 2450, 8281, 21, 726, 5684, 952, 16, 647, 5, 1], [21603, 10, 3234, 12, 18829, 26068, 56, 36, 5573, 21, 985, 18, 102, 4920, 239, 3500, 338, 37, 5209, 5780, 7, 898, 6996, 895, 45, 1600, 5, 94, 47, 4686, 57, 8, 616, 31, 7, 18176, 12838, 10846, 1483, 11, 7608, 21, 15993, 9145, 6, 11, 3, 9, 1126, 5336, 19, 271, 1702, 21, 8, 10730, 4907, 5, 1626, 354, 52, 9, 107, 22928, 6, 12864, 243, 985, 18, 102, 4920, 2601, 3500, 96, 8894, 36, 224, 3, 9, 600, 199, 1280, 37, 9145, 1888, 268, 1236, 113, 1111, 7, 12, 2384, 15622, 45, 2556, 15, 17, 1483, 3588, 334, 239, 243, 160, 2027, 7, 33, 583, 53, 3996, 2915, 399, 847, 5, 96, 6306, 196, 17, 908, 19, 6865, 46, 16242, 418, 13, 540, 21, 841, 114, 140, 6, 113, 744, 31, 17, 43, 3, 9, 294, 18, 715, 613, 5, 96, 196, 54, 320, 2177, 12, 8, 416, 215, 42, 78, 406, 8, 3516, 13, 149, 231, 540, 27, 183, 2887, 30, 82, 2027, 976, 255, 243, 5, 37, 1154, 47, 4382, 57, 1363, 10846, 1483, 16, 112, 6571, 32, 21, 18176, 16, 1186, 5, 96, 196, 11130, 12, 199, 69, 1021, 151, 129, 30, 16, 280, 6, 11, 48, 19, 8, 166, 1147, 16, 3, 6930, 30, 24, 976, 1363, 10846, 1483, 243, 5, 15993, 9145, 4983, 6043, 7, 3937, 6, 84, 5475, 66, 2601, 688, 16, 8, 616, 6, 56, 4285, 165, 1249, 18, 32, 883, 1016, 5743, 19077, 898, 18, 232, 18, 7248, 4142, 5, 71, 9212, 239, 4142, 12, 1189, 898, 12, 507, 215, 625, 7, 56, 92, 36, 3665, 5, 262, 2825, 11102, 12, 169, 8, 4142, 56, 661, 95, 12, 2664, 1660, 227, 8, 1139, 31, 7, 507, 189, 3591, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[282, 3, 26767, 3080, 411, 7, 12940, 2162, 66, 1566, 538, 2061, 56, 582, 3, 9, 6615, 2720, 7, 6, 8, 22982, 3141, 3256, 12, 15092, 8, 825, 270, 5, 1], [16111, 15, 26, 2601, 3500, 21, 898, 12, 507, 215, 625, 7, 56, 36, 3, 10671, 91, 16, 15993, 9145, 6, 34, 65, 118, 2162, 5, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS-6iXTkIrJT"
      },
      "source": [
        "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7d6e8cbabd024bce826b29a005931413",
            "16e752258009403eac6a52a3d8b0f891",
            "c49f878dbedd416e83e5aa566ff5b7cc",
            "956b23e18941444e8195d2c7f7c9303a",
            "0ed1f7c4a3894c9cb04f7d28ebcb6e0a",
            "e4baffec0a7e4a01939d54abffca1b84",
            "f529f9fa55614c12bbc517268d81e46f",
            "74947b0a988f4e6a8f7aac26c2143c76",
            "ffe4c08853c6487492d823606c173bb8",
            "05a2fc0d61204decbef972e9960dbdfe",
            "dc6ee9ca14804e47aca7191886d33bfa",
            "2ccab645109448ec83c3c5f886fae56f",
            "f7873d4555204362a059f1eaeec122a6",
            "a1a1bd4d236541c4add9c06ffacefcfc",
            "b5cc7cf5806a428283cc28dc565e06f4",
            "c3ecc75c2deb4ca3905dba184139ab51",
            "0dd20c5938e148ed89fe615f7f350128",
            "084a656378824cc29c27382d8eaa2456",
            "01ddce0d06da4312acb794e18c60f6c2",
            "8fb59dec81f54567b8a46211f27b9a2a",
            "5f7f9182df5344f88c06cc7f5a89b4d6",
            "6d3bf69cbbd84fd499cf64444727a3ea",
            "3ef77a81e86242aeaa9a6e2b96c99da3",
            "a222b23f62104d0a88e0a2568a59adda",
            "a1307ebf83ae4090b83506bdc90f71da",
            "a1941b132ceb4c568cb8d24568e8afde",
            "bd2ae99cc9fb4bd38514d5966455623c",
            "6b072a7089e74e3e8cbb8ff809a1cedb",
            "a75260a067b547b896b35ecb2c6e3318",
            "2e8ee2b8931746089cb0bc4bd5224131",
            "7ef9812e8310474894cb9c050d7869f7",
            "43e975dac2364ec1be04c55626ef8def",
            "9431db28cb2c4a89a5ed506371e0e16a"
          ]
        },
        "outputId": "149dcc0c-560d-4229-ace6-94e17a8b28eb"
      },
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d6e8cbabd024bce826b29a005931413"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ccab645109448ec83c3c5f886fae56f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ef77a81e86242aeaa9a6e2b96c99da3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voWiw8C7IrJV"
      },
      "source": [
        "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
        "\n",
        "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "## Fine-tuning the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBiW8UpKIrJW"
      },
      "source": [
        "Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a4efe5-3989-4aaf-a941-3c5759d7b4f5"
      },
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CczA5lJlIrJX"
      },
      "source": [
        "Note that  we don't get a warning like in our classification example. This means we used all the weights of the pretrained model and there is no randomly initialized head in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N8urzhyIrJY"
      },
      "source": [
        "To instantiate a `Seq2SeqTrainer`, we will need to define three more things. The most important is the [`Seq2SeqTrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bliy8zgjIrJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3bfe7b-c004-4a65-df11-5bd2fda1c916"
      },
      "source": [
        "batch_size = 4\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    \"test-summarization\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km3pGVdTIrJc"
      },
      "source": [
        "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the cell and customize the weight decay. Since the `Seq2SeqTrainer` will save the model regularly and our dataset is quite large, we tell it to make three saves maximum. Lastly, we use the `predict_with_generate` option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
        "\n",
        "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guAxulMsm47f"
      },
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sZOdRlRIrJd"
      },
      "source": [
        "The last thing to define for our `Seq2SeqTrainer` is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmvbnJ9JIrJd"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXuFTAzDIrJe"
      },
      "source": [
        "Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imY1oC3SIrJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf545e1-dd2a-46d5-83a9-9ee36b096943"
      },
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdzABDVcIrJg"
      },
      "source": [
        "We can now finetune our model by just calling the `train` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNx5pyRlIrJh",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "67469bf8-81f4-4a8b-eb15-e94556f921cd"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: document, id, summary. If document, id, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 03:10, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.058400</td>\n",
              "      <td>2.828076</td>\n",
              "      <td>19.511200</td>\n",
              "      <td>3.472400</td>\n",
              "      <td>15.273300</td>\n",
              "      <td>15.332800</td>\n",
              "      <td>18.677000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to test-summarization/checkpoint-500\n",
            "Configuration saved in test-summarization/checkpoint-500/config.json\n",
            "Model weights saved in test-summarization/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in test-summarization/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in test-summarization/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: document, id, summary. If document, id, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 01:47, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 05:38]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=3.058385986328125, metrics={'train_runtime': 191.1357, 'train_samples_per_second': 10.464, 'train_steps_per_second': 2.616, 'total_flos': 429342259150848.0, 'train_loss': 3.058385986328125, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MsgIYOiqipB"
      },
      "source": [
        "# !pip install -q GPUtil\n",
        "\n",
        "# import torch\n",
        "# from GPUtil import showUtilization as gpu_usage\n",
        "# from numba import cuda\n",
        "\n",
        "# def free_gpu_cache():\n",
        "#     print(\"Initial GPU Usage\")\n",
        "#     gpu_usage()                             \n",
        "\n",
        "#     torch.cuda.empty_cache()\n",
        "\n",
        "#     cuda.select_device(0)\n",
        "#     cuda.close()\n",
        "#     cuda.select_device(0)\n",
        "\n",
        "#     print(\"GPU Usage after emptying the cache\")\n",
        "#     gpu_usage()\n",
        "\n",
        "# free_gpu_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okTarr4cqohg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}